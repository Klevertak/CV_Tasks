{
  "cells": [
    {
      "metadata": {
        "_uuid": "996d22618b7fa8bd3619824432523019ec7ee234"
      },
      "cell_type": "markdown",
      "source": "# The Nature Conservancy Fisheries Monitoring"
    },
    {
      "metadata": {
        "_uuid": "4ce32d8ac2a30e3f719314a3d7c259f5db6a9198"
      },
      "cell_type": "markdown",
      "source": "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring"
    },
    {
      "metadata": {
        "_kg_hide-output": true,
        "_uuid": "784aaee522ae53eff2274a388350b1b1dd60649b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37b4be8a531dcd8e84bbf96c6d70b6dd0ff7ed4c",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "!ls -ltr ../input/boxes/boxes/boxes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b3920f91584b81ca1a0780be8bfcf3bef4b9983",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "ls -ltr ../input/the-nature-conservancy-fisheries-monitoring/train",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "263db29157d5633d6f9e7340ab5efec72c677b66"
      },
      "cell_type": "markdown",
      "source": "# Загружаем разметку"
    },
    {
      "metadata": {
        "_uuid": "76496f443d36d16b961aeef10b365e3822b06a2b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import os\nimport json\nfrom glob import glob\n\n# TODO: скачайте данные и сохраните в директорию:\nTRAIN_PREFIX = '../input/the-nature-conservancy-fisheries-monitoring/train'\n\ndef load_boxes():\n    boxes = dict()\n    for path in glob('../input/boxes/boxes/boxes/*.json'):\n        label = os.path.basename(path).split('_', 1)[0]\n        with open(path) as src:\n            boxes[label] = json.load(src)\n            for annotation in boxes[label]:\n                basename = os.path.basename(annotation['filename'])\n                annotation['filename'] = os.path.join(TRAIN_PREFIX, label.upper(), basename)\n            for annotation in boxes[label]:\n                for rect in annotation['annotations']:\n                    rect['x'] += rect['width'] / 2\n                    rect['y'] += rect['height'] / 2\n    return boxes\n\ndef draw_boxes(annotation, rectangles=None, image_size=None):\n    \n    def _draw(img, rectangles, scale_x, scale_y, color=(0, 255, 0)):\n        for rect in rectangles:\n            pt1 = (int((rect['x'] - rect['width'] / 2) * scale_x),\n                   int((rect['y'] - rect['height'] / 2) * scale_y))\n            pt2 = (int((rect['x'] + rect['width'] / 2) * scale_x),\n                   int((rect['y'] + rect['height'] / 2) * scale_y))\n            img = cv2.rectangle(img.copy(), pt1, pt2, \n                                color=color, thickness=4)        \n        return img\n    \n    scale_x, scale_y = 1., 1.\n    \n    img = cv2.imread(annotation['filename'], cv2.IMREAD_COLOR)[...,::-1]\n    if image_size is not None:\n        scale_x = 1. * image_size[0] / img.shape[1]\n        scale_y = 1. * image_size[1] / img.shape[0]\n        img = cv2.resize(img, image_size)\n        \n    img = _draw(img, annotation['annotations'], scale_x, scale_y)\n    \n    if rectangles is not None:\n        img = _draw(img, rectangles, 1., 1., (255, 0, 0))\n\n    return img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "84e41df6b52ba646af87d7b2debe900cdd7ca9c5"
      },
      "cell_type": "markdown",
      "source": "### Визуализируем разметку"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c49053ba458482b6684ee9bdfe907e41fbb80fdd",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "boxes = load_boxes()  # разметка детекций",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "431e227f7bd9dc79d1d7e8f89054eb071352cec1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df =pd.DataFrame([(k, len(v)) for k, v in boxes.items()],\n             columns=['class', 'count'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "436cd9dda9dd2f8953fad11a004799dbd3d88346",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92accc6fa356b4d5d6513e2e727265ef602f9917",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "classes_weights = df['count']/ df['count'].sum()\nclasses_weights",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bb49d388931db2cbd5d8f08b9104299ca90a8c5a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(6, 6), dpi=120)\nimg = draw_boxes(boxes['lag'][17])\nplt.imshow(img)\nplt.title('{}x{}'.format(*img.shape));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0caa7502a0deb8e5e18773b6d2be8ed2f8d0dd4f"
      },
      "cell_type": "markdown",
      "source": "### Распределение размеров разметки"
    },
    {
      "metadata": {
        "_uuid": "8db3e3e9aa63c1216d3a1f13526d74ab3abe31a8",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "annotations = sum([box['annotations']\n                  for box in sum(boxes.values(), [])], [])\n\nwidths = [rect['width'] for rect in annotations]\nheights = [rect['height'] for rect in annotations]\n\nplt.hist(widths)\nplt.hist(heights);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b01ffd790e6e7a81bfee104faa4bfa84ad7597c8"
      },
      "cell_type": "markdown",
      "source": "# Экстрактор признаков"
    },
    {
      "metadata": {
        "_uuid": "f3e6d68bd5e0c8a97319185f25a3b25673482606",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "IMG_HEIGHT = 750\nIMG_WIDTH = 1200\n\nfeatures = keras.applications.vgg16.VGG16(include_top=False,\n                                          weights='imagenet',\n                                          input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nfeature_tensor = features.layers[-1].output\n\n# дообучаем последние 5 слоев\nfor layer in features.layers[:-5]:\n    layer.trainable = False",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ac4e46072546760703354bd43fa09c5d6bd69fb9"
      },
      "cell_type": "markdown",
      "source": "# Сетка якорей (anchor grid)"
    },
    {
      "metadata": {
        "_uuid": "9d267722da49aad29f4bd4b625473295c3293e5f",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "FEATURE_SHAPE = (feature_tensor.shape[1].value,\n                 feature_tensor.shape[2].value)\n\nGRID_STEP_H = IMG_HEIGHT / FEATURE_SHAPE[0]\nGRID_STEP_W = IMG_WIDTH / FEATURE_SHAPE[1]\n\nANCHOR_WIDTH = 150.\nANCHOR_HEIGHT = 150. \n\nANCHOR_CENTERS = np.mgrid[GRID_STEP_H/2:IMG_HEIGHT:GRID_STEP_H,\n                          GRID_STEP_W/2:IMG_WIDTH:GRID_STEP_W]\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f92bd80d8901c206b0220c01c8a80bf0513875e2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "LABELS_DICT = {}\nREVERSE_DICT = {}\n\nfor i,x in enumerate(boxes.keys()):\n    LABELS_DICT[x] = i\n    REVERSE_DICT[i] = x\n\nCLASSES_NUM = len(LABELS_DICT)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9b624f9ae11ed38fe228dd3ef118cf27e23fcfb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "LABELS_DICT ,CLASSES_NUM, boxes.keys(), REVERSE_DICT",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "3b91ec74a72692f7eae0d720dc12b97931a9d4bb"
      },
      "cell_type": "code",
      "source": "for x in boxes.keys():\n    for b in boxes[x]:\n        b['label'] = x",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bcb3fa8f8874d1b9dbb4fe1ecca490f4ebb7d255",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from keras.utils.np_utils import to_categorical   \n\ncategorical_labels = to_categorical(list(REVERSE_DICT.keys()), num_classes=CLASSES_NUM)\ncategorical_labels",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4dfe06e528ead274fbaf11231005d4ff5697f636",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "REVERSE_DICT",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def iou(rect, x_scale, y_scale, anchor_x, anchor_y,\n        anchor_w=ANCHOR_WIDTH, anchor_h=ANCHOR_HEIGHT):\n    \n    rect_x1 = (rect['x'] - rect['width'] / 2) * x_scale\n    rect_x2 = (rect['x'] + rect['width'] / 2) * x_scale\n    \n    rect_y1 = (rect['y'] - rect['height'] / 2) * y_scale\n    rect_y2 = (rect['y'] + rect['height'] / 2) * y_scale\n    \n    anch_x1, anch_x2 = anchor_x - anchor_w / 2, anchor_x + anchor_w / 2\n    anch_y1, anch_y2 = anchor_y - anchor_h / 2, anchor_y + anchor_h / 2\n    \n    dx = (min(rect_x2, anch_x2) - max(rect_x1, anch_x1))\n    dy = (min(rect_y2, anch_y2) - max(rect_y1, anch_y1))\n    \n    intersection = dx * dy if (dx > 0 and dy > 0) else 0.\n    \n    anch_square = (anch_x2 - anch_x1) * (anch_y2 - anch_y1)\n    rect_square = (rect_x2 - rect_x1) * (rect_y2 - rect_y1)\n    union = anch_square + rect_square - intersection\n    \n    return intersection / union\n\ndef encode_anchors(annotation, img_shape, label_name, iou_thr=0.5):\n    encoded = np.zeros(shape=(FEATURE_SHAPE[0],\n                              FEATURE_SHAPE[1], 5+CLASSES_NUM), dtype=np.float32)\n    x_scale = 1. * IMG_WIDTH / img_shape[1]\n    y_scale = 1. * IMG_HEIGHT / img_shape[0]\n    for rect in annotation['annotations']:\n        scores = []\n        for row in range(FEATURE_SHAPE[0]):\n            for col in range(FEATURE_SHAPE[1]):\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                score = iou(rect, x_scale, y_scale, anchor_x, anchor_y)\n                scores.append((score, anchor_x, anchor_y, row, col))\n        \n        scores = sorted(scores, reverse=True)\n        if scores[0][0] < iou_thr:\n            scores = [scores[0]]  # default anchor\n        else:\n            scores = [e for e in scores if e[0] > iou_thr]\n#TODO add classes one hot\n        class_num = LABELS_DICT[label_name]\n    \n        for score, anchor_x, anchor_y, row, col in scores:\n            dx = (anchor_x - rect['x'] * x_scale) / ANCHOR_WIDTH\n            dy = (anchor_y - rect['y'] * y_scale) / ANCHOR_HEIGHT\n            dw = (ANCHOR_WIDTH - rect['width'] * x_scale) / ANCHOR_WIDTH\n            dh = (ANCHOR_HEIGHT - rect['height'] * y_scale) / ANCHOR_HEIGHT\n    \n            encoded[row, col] = [1., dx, dy, dw, dh]+list(categorical_labels[class_num])\n        \n    return encoded\n\ndef _sigmoid(x):\n    return 1. / (1. + np.exp(-x))\n\ndef decode_prediction(prediction, conf_thr=0.1):\n    rectangles = []\n    for row in range(FEATURE_SHAPE[0]):\n        for col in range(FEATURE_SHAPE[1]):\n#             print(prediction[row, col])\n#             print(prediction[row, col])\n            out_list = prediction[row, col].tolist()\n            logit, dx, dy, dw, dh, one_hot_class =out_list[0], out_list[1], out_list[2], out_list[3],out_list[4], out_list[5:]\n            label_index = np.argmax(one_hot_class, axis=0) \n            conf = _sigmoid(logit)\n#             print(logit, dx, dy, dw, dh, one_hot_class )\n            if conf > conf_thr:\n                anchor_x = ANCHOR_CENTERS[1, row, col]\n                anchor_y = ANCHOR_CENTERS[0, row, col]\n                rectangles.append({'x': anchor_x - dx * ANCHOR_WIDTH,\n                                   'y': anchor_y - dy * ANCHOR_HEIGHT,\n                                   'width': ANCHOR_WIDTH - dw * ANCHOR_WIDTH,\n                                   'height': ANCHOR_HEIGHT - dh * ANCHOR_HEIGHT,\n                                   'conf': conf,\n                                   'label': REVERSE_DICT[label_index]})\n    return rectangles",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7187f32903a8bd4dd647b2cc7d8bd819c1478a9f"
      },
      "cell_type": "markdown",
      "source": "### Валидация енкодинга/декодинга"
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true,
        "_uuid": "925a6fcb1ccb5b956c7444f1448ff5948fc9df85",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "example = boxes['alb'][178]\n# print(boxes['alb'][178]['label'])\nencoded = encode_anchors(example, (IMG_HEIGHT, IMG_WIDTH), boxes['alb'][178]['label'])\n# print(encoded[0])\n\ndecoded = decode_prediction(encoded, conf_thr=0.5)\ndecoded = sorted(decoded, key = lambda e: -e['conf'])\n# print(decoded)\nplt.figure(figsize=(6, 6), dpi=120)\nplt.title('{}'.format(decoded[0]['label']));\nplt.imshow(draw_boxes(example, decoded[:10]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "69b77cba0531fd1ed1c2634e929bee24ac068f7a"
      },
      "cell_type": "markdown",
      "source": "## Функция потерь"
    },
    {
      "metadata": {
        "_uuid": "52a6271f7fabac76acec4013093bc35a7f1dc335",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "K = tf.keras.backend\n\n\n# def weighted_categorical_crossentropy(y_true, y_pred, weights):\n#     nb_cl = len(weights)\n#     final_mask = K.zeros_like(y_pred[:, 0])\n#     y_pred_max = K.max(y_pred, axis=1)\n#     y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n#     y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n#     for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n#         final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n#     cross_ent = K.categorical_crossentropy(y_pred, y_true, from_logits=False)\n#     return cross_ent * final_mask\ndef classification_loss(y_true, y_pred):\n    class_loss =  K.categorical_crossentropy(y_true[..., 5:], \n                                      y_pred[..., 5:],\n                                      from_logits=False)\n    return class_loss\n\n\ndef confidence_loss(y_true, y_pred):\n    conf_loss = K.binary_crossentropy(y_true[..., 0], \n                                      y_pred[..., 0],\n                                      from_logits=True)\n    return conf_loss\n\ndef smooth_l1(y_true, y_pred):\n    abs_loss = K.abs(y_true[..., 1:] - y_pred[..., 1:])\n    square_loss = 0.5 * K.square(y_true[..., 1:] - y_pred[..., 1:])\n    mask = K.cast(K.greater(abs_loss, 1.), 'float32')\n    total_loss = (abs_loss - 0.5) * mask + 0.5 * square_loss * (1. - mask)\n    return K.sum(total_loss, axis=-1)\n\ndef total_loss(y_true, y_pred, neg_pos_ratio=3):\n    batch_size = K.shape(y_true)[0]\n    \n    # TODO: добавьте функцию потерь для классификации детекции\n    \n    y_true = K.reshape(y_true, (batch_size, -1, 5+CLASSES_NUM))\n    y_pred = K.reshape(y_pred, (batch_size, -1, 5+CLASSES_NUM))\n    class_true = K.reshape(y_true[...,5:],(-1,))\n    class_pred =  K.reshape(y_pred[...,5:],(-1,))\n#     print(class_true, class_pred)\n    y_true = y_true[...,:5]\n    y_pred = y_pred[...,:5]\n\n    #classification loss\n    class_loss = K.categorical_crossentropy(class_true, class_pred, from_logits=False)\n    \n    # confidence loss\n    conf_loss = confidence_loss(y_true, y_pred)\n    \n    # smooth l1 loss\n    loc_loss = smooth_l1(y_true, y_pred)\n    \n    # positive examples loss\n    pos_conf_loss = K.sum(conf_loss * y_true[..., 0], axis=-1)\n    pos_loc_loss = K.sum(loc_loss * y_true[..., 0], axis=-1)\n    \n    # negative examples loss\n    anchors = K.shape(y_true)[1]\n    num_pos = K.sum(y_true[..., 0], axis=-1)\n    num_pos_avg = K.mean(num_pos)\n    num_neg = K.min([neg_pos_ratio * (num_pos_avg) + 1., K.cast(anchors, 'float32')])\n    \n    # hard negative mining\n    neg_conf_loss, _ = tf.nn.top_k(conf_loss * (1. - y_true[..., 0]),\n                                   k=K.cast(num_neg, 'int32'))\n\n    neg_conf_loss = K.sum(neg_conf_loss, axis=-1)\n    \n    # total conf loss\n    total_conf_loss = (neg_conf_loss + pos_conf_loss) / (num_neg + num_pos + 1e-32)\n    loc_loss = pos_loc_loss / (num_pos + 1e-32)\n    \n    return total_conf_loss + 0.5 * loc_loss + class_loss",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "457c64f24b74141b39a2fd5a125311dc80bcbd9f"
      },
      "cell_type": "markdown",
      "source": "## Загрузка данных"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "4376e1a62a0977c1395f640dff502fdc686ae132"
      },
      "cell_type": "code",
      "source": "def load_img(path, target_size=(IMG_WIDTH, IMG_HEIGHT)):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)[...,::-1]\n    img_shape = img.shape\n    img_resized = cv2.resize(img, target_size)\n    return img_shape, keras.applications.vgg16.preprocess_input(img_resized.astype(np.float32))\n\ndef data_generator(boxes, batch_size=32):\n    boxes = sum(boxes.values(), [])\n    while True:\n        random.shuffle(boxes)\n        for i in range(len(boxes)//batch_size):\n            X, y = [], []\n            for j in range(i*batch_size,(i+1)*batch_size):\n                img_shape, img = load_img(boxes[j]['filename'])\n                # TODO: добавьте one-hot encoding в разметку для классов\n                y.append(encode_anchors(boxes[j], img_shape, boxes[j]['label']))\n                X.append(img)\n            yield np.array(X), np.array(y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "dababc8ff67affb4cab94ec52bc7252b1b4ac761"
      },
      "cell_type": "code",
      "source": "# tmp_boxes = sum(boxes.values(), [])\n# tmp_boxes[0]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "95576135d688926268123945f139df2e11f72f91"
      },
      "cell_type": "markdown",
      "source": "## Добавляем выход детектора"
    },
    {
      "metadata": {
        "_uuid": "a8904e155a9d956eecccd59a9b104bcfd20c44e1",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "output = keras.layers.BatchNormalization()(feature_tensor)\n\n# TODO: добавьте выходы для классификации детекции\noutput = keras.layers.Conv2D(5+CLASSES_NUM,\n                             kernel_size=(1, 1), \n                             activation='linear',\n                             kernel_regularizer='l2')(output)\n\nmodel = keras.models.Model(inputs=features.inputs, outputs=output)\n# model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "39a605bac397630af42ab5671f0332b3a8938fff"
      },
      "cell_type": "markdown",
      "source": "## Обучение"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ee2ee415d4365086228fc3ca5b087c27de428ac",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "adam = keras.optimizers.Adam(lr=1e-3, decay=1e-6)\nmodel.compile(optimizer=adam, \n              loss=total_loss,\n              metrics={'conf_loss': confidence_loss, 'class_loss': classification_loss})",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "88d52a3e5e2f887dcf4cb295c62c3820c97f0db9",
        "scrolled": false,
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "batch_size = 5\nsteps_per_epoch = sum(map(len, boxes.values()), 0) / batch_size\n\ngen = data_generator(boxes, batch_size=batch_size)\n\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    'weights.{epoch:02d}-{loss:.3f}.hdf5',\n    monitor='loss',\n    verbose=1,  \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto', period=1)\n\nmodel.fit_generator(generator=gen, \n                    steps_per_epoch=steps_per_epoch,\n                    epochs=10000,\n                    callbacks=[checkpoint])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f71f03b08b2ee11141dc23a60f39b657d13062f8"
      },
      "cell_type": "markdown",
      "source": "## Результат работы детектора"
    },
    {
      "metadata": {
        "_uuid": "6d6d87b271aad9b6f5135870c464f613fce3a31c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "example = boxes['lag'][17]\n\n_, sample_img = load_img(example['filename'])\npred = model.predict(np.array([sample_img,]))[0]\n\ndecoded = decode_prediction(pred, conf_thr=0.)\ndecoded = sorted(decoded, key=lambda e: -e['conf'])\n\nplt.figure(figsize=(6, 6), dpi=120)\nimg = draw_boxes(example, decoded[:3], (IMG_WIDTH, IMG_HEIGHT))\nplt.imshow(img)\nplt.title('{}x{}'.format(*img.shape));",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "78a728815dc76f3386ea4261a9c1bbbeb375099a"
      },
      "cell_type": "markdown",
      "source": "## Агрегация результатов"
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": false,
        "_uuid": "a8b14d6e59bfddd078785f3f1698fba4352f545f"
      },
      "cell_type": "code",
      "source": "# TODO: предскажите класс рыбы для фотографии из тестовой выборки\n#\n# Подготовьте файл с предсказаниями вероятностей для каждой фотографии:\n# image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\n# img_00001.jpg,1,0,0,0,0,...,0\n# img_00002.jpg,0.3,0.1,0.6,0,...,0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}